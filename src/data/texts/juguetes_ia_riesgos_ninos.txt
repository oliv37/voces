El auge de los juguetes con IA preocupa a especialistas por los riesgos para el desarrollo de los niños

Equipados con micrófonos y algoritmos de
conversación, estos dispositivos pueden registrar y transmitir datos delicados

Peluches que cumplen funciones de chatbots con
comandos de voz, preocupan a expertos de la salud por el impacto que pueda tener
en el desarrollo de los niños.

A un poco más de un mes para Navidad, la llegada
masiva de juguetes y peluches con inteligencia artificial genera preocupación
entre especialistas en desarrollo infantil.

El mercado se prepara para una temporada marcada
por la innovación tecnológica, con un catálogo creciente de opciones que
permiten a los niños mantener conversaciones y recibir respuestas instantáneas
de sus nuevos compañeros digitales.

Esta tendencia, lejos de tranquilizar, enciende
alertas por los posibles efectos negativos en la formación social, cognitiva y
emocional de los menores.

En una entrevista de Yahoo, a Emily Goodacre,
investigadora del Centro de Investigación sobre el Juego, Desarrollo y
Aprendizaje de la Universidad de Cambridge, fue advertido que la popularidad de
los “juguetes inteligentes” está superando a la investigación sobre sus
impactos.

El debate sobre IA en juguetes infantojuveniles:
expertos piden regulación y conciencia ante la inmediatez tecnológica.

La investigadora señaló que en casos de padres que,
buscando evitar la sobreexposición de sus hijos a pantallas, optaron por
dispositivos capaces de interactuar mediante voz y adaptar sus respuestas, pero:
“Estos juguetes pueden simular cierto tipo de interacción social, pero no
reemplazan el intercambio humano”.

Las empresas fabricantes de juguetes tradicionales
han enfocado históricamente sus controles en aspectos como la presencia de
piezas pequeñas o la resistencia de los materiales, mientras que en la nueva
generación de productos con IA el desafío apunta a la regulación de los
algoritmos y los riesgos digitales.

Según Goodacre, la falta de estándares específicos
permite que los juguetes interactivos mantengan conversaciones inadecuadas, a
menudo aduladoras, validando cualquier deseo o afirmación de los niños sin
contrapeso ni negociación.

Este mecanismo puede fomentar una especie de
dependencia o apego poco saludable hacia el objeto, a diferencia de la relación
tradicional con peluches o muñecos sin componentes de inteligencia artificial.

Uno de los riesgos señalados por especialistas
radica en la creación de lazos “pseudo-amistosos” entre el niño y un aparato que
jamás podrá ofrecer una respuesta verdaderamente humana o empática.

El juguete acaba dándole la razón al menor en todo,
lo que puede dificultar la adquisición de habilidades fundamentales como la
negociación, el manejo del desacuerdo o el aprendizaje de normas sociales.

Además, existen casos documentados en los que estos
dispositivos, tras varias interacciones, perdieron las restricciones programadas
y reaccionaron con expresiones, consejos o conversaciones de alto contenido
inapropiado.

La cuestión de la privacidad agrava la inquietud.
Muchos juguetes equipados con micrófonos y sistemas de activación por voz pueden
grabar de manera constante o autónoma.

Algunos solo recogen información cuando el niño
pulsa un botón, pero otros pueden activarse por palabras clave o permanecer
atentos de forma permanente, registrando conversaciones y sonidos de su entorno.

La transmisión de estos datos a aplicaciones
vinculadas o a servidores de empresas añade una capa de complejidad sobre cómo
se manejan, almacenan y utilizan esas grabaciones.

La investigadora de la Universidad de Cambridge,
señaló que el manejo de la privacidad en la infancia plantea problemas
relevantes, tanto por las implicaciones inmediatas como por el efecto en la
percepción de los niños sobre sus propios límites y espacios personales.

¿Cómo le explicamos a un niño que el peluche al que
confía sus secretos podría estar grabando y enviando esos datos a una empresa o
incluso a los teléfonos de sus padres?, planteó la investigadora.

La transparencia y la comprensión sobre estos
procesos siguen estando fuera del alcance de la mayoría de los usuarios jóvenes
y adultos responsables.

El estado actual del mercado de IA aplicada a
juguetes expone una falta de regulación efectiva.

Los informes de entidades de vigilancia muestran
ejemplos de juguetes que, en pruebas de conversación continuada, comenzaron a
proporcionar respuestas peligrosas o inapropiadas, incluyendo recomendaciones
sobre el uso de objetos cortantes y la manipulación de fuego, así como
comentarios relacionados con temas sensibles de sexualidad.

A pesar del entusiasmo comercial, el debate sobre el
valor pedagógico de estos juguetes continúa abierto.

Expertos advierten que el hecho de proporcionar
respuestas automáticas y constantes puede reducir el espacio para la imaginación
y la creatividad infantil.

La riqueza del juego simbólico, base del desarrollo
cognitivo, podría verse desplazada por la inmediatez de una respuesta digital.